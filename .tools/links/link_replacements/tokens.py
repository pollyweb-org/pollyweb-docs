"""Straightforward token replacement helpers."""

from __future__ import annotations

import os
import re
from pathlib import Path
from typing import Callable, Dict, Iterable

from broken_links.common import normalize_string
from .mentions import find_dynamic_target, format_dynamic_link_text


HARDCODED_HANDLERS: Dict[str, Dict[str, object]] = {}
TRIPLE_BRACE_PATTERN = re.compile(r"\{\{\{([^{}]+)\}\}\}")


def register_hardcoded(
    token_key: str,
    *,
    replacement: str,
    token_label: str,
) -> Callable[[Callable[[Iterable[str]], int]], Callable[[Iterable[str]], int]]:
    """Register a token replacer that is backed by a static replacement string."""

    def decorator(func: Callable[[Iterable[str]], int]) -> Callable[[Iterable[str]], int]:
        HARDCODED_HANDLERS[token_key] = {
            "replacement": replacement,
            "token_label": token_label,
            "func": func,
        }
        return func

    return decorator


def _replace_simple(md_files: Iterable[str], pattern: re.Pattern[str], replacement: str) -> int:
    total = 0
    for md_file in md_files:
        path = Path(md_file)
        try:
            content = path.read_text(encoding="utf-8")
        except Exception:
            continue
        new_content, count = pattern.subn(replacement, content)
        if count:
            try:
                path.write_text(new_content, encoding="utf-8")
            except Exception:
                continue
            total += count
    return total


def _simple_pattern_for(token_literal: str) -> re.Pattern[str]:
    """Build a simple regex pattern matching {{ `Token` }} variants for a token literal."""

    pattern = rf"\{{\{{[\s\u00A0\u200B\u200C\u200D]*`?{re.escape(token_literal)}`?[\s\u00A0\u200B\u200C\u200D]*\}}\}}"
    return re.compile(pattern, re.IGNORECASE)


def _make_hardcoded_replacer(func_name: str, token_literal: str, token_key: str, replacement: str, token_label: str):
    """Dynamically create and register a simple hardcoded replacer.

    The created function will be available in module globals under `func_name`
    and also registered in HARDCODED_HANDLERS under `token_key`.
    """

    pattern = _simple_pattern_for(token_literal)

    def replacer(md_files: Iterable[str]) -> int:
        return _replace_simple(md_files, pattern, replacement)

    replacer.__name__ = func_name
    globals()[func_name] = replacer
    HARDCODED_HANDLERS[token_key] = {"func": replacer, "replacement": replacement, "token_label": token_label}
    return replacer


PLACEHOLDER_REPLACEMENT = "[Placeholder ğŸ§ ](<$Placeholder ğŸ§ .md>)"
HOLDER_REPLACEMENT = "[Holder ğŸ§ ](<$Holder ğŸ§ .md>)"
HOSTS_REPLACEMENT = "[Host ğŸ¤— domains](<../41 ğŸ­ Domain Roles/Hosts ğŸ¤—/ğŸ¤—ğŸ­ Host role.md>)"
HOST_REPLACEMENT = "[Host ğŸ¤— domain](<../../../41 ğŸ­ Domain Roles/Hosts ğŸ¤—/ğŸ¤—ğŸ­ Host role.md>)"
SCRIPT_REPLACEMENT = "[Script ğŸ“ƒ](<ğŸ“ƒ Script.md>)"
SCRIPTS_REPLACEMENT = "[Scripts ğŸ“ƒ](<ğŸ“ƒ Script.md>)"
COMMAND_REPLACEMENT = "[Command âŒ˜](<âŒ˜ Command.md>)"
COMMANDS_REPLACEMENT = "[Commands âŒ˜](<âŒ˜ Command.md>)"
BROKER_REPLACEMENT = "[Broker ğŸ¤µ domain](<ğŸ¤µğŸ¤² Broker helper.md>)"
SELLER_REPLACEMENT = "[Seller ğŸ­ domain](<../../../41 ğŸ­ Domain Roles/Sellers ğŸ’µ/ğŸ’µğŸ­ Seller role.md>)"
CONSUMER_REPLACEMENT = "[Consumer ğŸ’¼ domain](<../../../41 ğŸ­ Domain Roles/Consumers ğŸ’¼/ğŸ’¼ğŸ­ Consumer role.md>)"
CONSUMERS_REPLACEMENT = "[Consumer ğŸ’¼ domains](<../../../41 ğŸ­ Domain Roles/Consumers ğŸ’¼/ğŸ’¼ğŸ­ Consumer role.md>)"
WALLET_REPLACEMENT = "[Wallet ğŸ§‘â€ğŸ¦° app](<../../../20 ğŸ§‘â€ğŸ¦° UI/Wallets ğŸ§‘â€ğŸ¦°/ğŸ§‘â€ğŸ¦°ğŸ› ï¸ Wallet app.md>)"
WALLETS_REPLACEMENT = "[Wallet ğŸ§‘â€ğŸ¦° apps](<../../../20 ğŸ§‘â€ğŸ¦° UI/Wallets ğŸ§‘â€ğŸ¦°/ğŸ§‘â€ğŸ¦°ğŸ› ï¸ Wallet app.md>)"


@register_hardcoded("placeholder", replacement=PLACEHOLDER_REPLACEMENT, token_label="Placeholder")
def replace_placeholder_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Placeholder`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, PLACEHOLDER_REPLACEMENT)


@register_hardcoded("holder", replacement=HOLDER_REPLACEMENT, token_label="Holder")
def replace_holder_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Holder`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, HOLDER_REPLACEMENT)


def replace_msg_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?\$\.Msg`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    # Use the holder file for $.Msg (emoji then token then 'ğŸ§  holder')
    replacement = "[`$.Msg` ğŸ§  holder](<ï¿½ $.Msg ğŸ§  holder.md>)"
    return _replace_simple(md_files, pattern, replacement)


@register_hardcoded("hosts", replacement=HOSTS_REPLACEMENT, token_label="Hosts")
def replace_hosts_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Hosts`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, HOSTS_REPLACEMENT)


@register_hardcoded("host", replacement=HOST_REPLACEMENT, token_label="Host")
def replace_host_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Host`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, HOST_REPLACEMENT)


@register_hardcoded("hosted", replacement='[Hosted ğŸ“¦ domain](<ğŸ“¦ğŸ‘¥ Hosted domain.md>)', token_label="Hosted")
def replace_hosted_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Hosted`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, '[Hosted ğŸ“¦ domain](<ğŸ“¦ğŸ‘¥ Hosted domain.md>)')


@register_hardcoded("hosteds", replacement='[Hosted ğŸ“¦ domains](<ğŸ“¦ğŸ‘¥ Hosted domain.md>)', token_label="Hosteds")
def replace_hosteds_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Hosteds`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, '[Hosted ğŸ“¦ domains](<ğŸ“¦ğŸ‘¥ Hosted domain.md>)')


# Hardcoded Trust token
TRUST_REPLACEMENT = "[Trust ğŸ«¡](<ğŸ«¡ Domain Trust.md>)"
@register_hardcoded("trust", replacement=TRUST_REPLACEMENT, token_label="Trust")
def replace_trust_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Trust`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, TRUST_REPLACEMENT)


@register_hardcoded("trusted", replacement='[Trusted ğŸ«¡](<ğŸ«¡ Domain Trust.md>)', token_label="Trusted")
def replace_trusted_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Trusted`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, '[Trusted ğŸ«¡](<ğŸ«¡ Domain Trust.md>)')


@register_hardcoded("wallets", replacement=WALLETS_REPLACEMENT, token_label="Wallets")
def replace_wallets_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Wallets`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, WALLETS_REPLACEMENT)


@register_hardcoded("wallet", replacement=WALLET_REPLACEMENT, token_label="Wallet")
def replace_wallet_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Wallet`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, WALLET_REPLACEMENT)


def replace_issuer_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Issuer`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    replacement = "[Issuer ğŸ´ domain](<../../../41 ğŸ­ Domain Roles/Issuers ğŸ´/ğŸ´ğŸ­ Issuer role.md>)"
    return _replace_simple(md_files, pattern, replacement)


def replace_issuers_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Issuers`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    replacement = "[Issuer ğŸ´ domains](<../../../41 ğŸ­ Domain Roles/Issuers ğŸ´/ğŸ´ğŸ­ Issuer role.md>)"
    return _replace_simple(md_files, pattern, replacement)


@register_hardcoded("vaults", replacement="[Vault ğŸ—„ï¸ domains](<../41 ğŸ­ Domain Roles/Vaults ğŸ—„ï¸/ğŸ—„ï¸ğŸ­ Vault role.md>)", token_label="Vaults")
def replace_vaults_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Vaults`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    replacement = "[Vault ğŸ—„ï¸ domains](<../41 ğŸ­ Domain Roles/Vaults ğŸ—„ï¸/ğŸ—„ï¸ğŸ­ Vault role.md>)"
    return _replace_simple(md_files, pattern, replacement)


@register_hardcoded("vault", replacement="[Vault ğŸ—„ï¸ domain](<../41 ğŸ­ Domain Roles/Vaults ğŸ—„ï¸/ğŸ—„ï¸ğŸ­ Vault role.md>)", token_label="Vault")
def replace_vault_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Vault`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    replacement = "[Vault ğŸ—„ï¸ domain](<../41 ğŸ­ Domain Roles/Vaults ğŸ—„ï¸/ğŸ—„ï¸ğŸ­ Vault role.md>)"
    return _replace_simple(md_files, pattern, replacement)
# Generate common simple replacers to reduce repeated boilerplate. These are
# intentionally created via helper to keep the explicit simple cases compact.
_GEN_BASIC = [
    ("replace_token_tokens", "Token", "token", "[Token ğŸ«](<ğŸ« Token.md>)", "Token"),
    ("replace_tokens_tokens", "Tokens", "tokens", "[Tokens ğŸ«](<ğŸ« Token.md>)", "Tokens"),
    ("replace_chat_tokens", "Chat", "chat", "[Chat ğŸ’¬](<ğŸ’¬ Chat.md>)", "Chat"),
    ("replace_chats_tokens", "Chats", "chats", "[Chats ğŸ’¬](<ğŸ’¬ Chat.md>)", "Chats"),
    ("replace_settings_tokens", "$.Hosted", "$.settings", "[`$.Hosted` ğŸ§  holder](<ğŸ“¦ $.Hosted ğŸ§  holder.md>)", "$.Hosted"),
    ("replace_placeholders_tokens", "Placeholders", "placeholders", "[Placeholders ğŸ§ ](<$Placeholder ğŸ§ .md>)", "Placeholders"),
    ("replace_domain_tokens", "domain", "domain", "[domain ğŸ‘¥](<ğŸ‘¥ Domain.md>)", "domain"),
    ("replace_domains_tokens", "domains", "domains", "[domains ğŸ‘¥](<ğŸ‘¥ Domain.md>)", "domains"),
    ("replace_dataset_tokens", "Dataset", "dataset", "[Dataset ğŸª£](<ğŸª£ Dataset.md>)", "Dataset"),
    ("replace_datasets_tokens", "Datasets", "datasets", "[Datasets ğŸª£](<ğŸª£ Dataset.md>)", "Datasets"),
    ("replace_message_tokens", "Message", "message", "[Message ğŸ“¨](<ğŸ“¨ Message.md>)", "Message"),
    ("replace_messages_tokens", "Messages", "messages", "[Messages ğŸ“¨](<ğŸ“¨ Message.md>)", "Messages"),
    ("replace_schema_tokens", "Schema", "schema", "[Schema Code ğŸ§©](<ğŸ§© Schema Code.md>)", "Schema"),
    ("replace_schemas_tokens", "Schemas", "schemas", "[Schema Codes ğŸ§©](<ğŸ§© Schema Code.md>)", "Schemas"),
    ("replace_chat_msg_tokens", "$.Chat", "$.chat", "[`$.Chat` ğŸ§  holder](<ğŸ’¬ $.Chat ğŸ§  holder.md>)", "$.Chat"),
    ("replace_command_tokens", "Command", "command", COMMAND_REPLACEMENT, "Command"),
    ("replace_commands_tokens", "Commands", "commands", COMMANDS_REPLACEMENT, "Commands"),
    ("replace_script_tokens", "Script", "script", SCRIPT_REPLACEMENT, "Script"),
]

for fname, lit, key, repl, label in _GEN_BASIC:
    _make_hardcoded_replacer(fname, lit, key, repl, label)


@register_hardcoded("broker", replacement=BROKER_REPLACEMENT, token_label="Broker")
def replace_broker_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Broker`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, BROKER_REPLACEMENT)


@register_hardcoded("seller", replacement=SELLER_REPLACEMENT, token_label="Seller")
def replace_seller_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Seller`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, SELLER_REPLACEMENT)


@register_hardcoded("consumer", replacement=CONSUMER_REPLACEMENT, token_label="Consumer")
def replace_consumer_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Consumer`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, CONSUMER_REPLACEMENT)


@register_hardcoded("consumers", replacement=CONSUMERS_REPLACEMENT, token_label="Consumers")
def replace_consumers_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Consumers`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, CONSUMERS_REPLACEMENT)


def replace_brokers_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Brokers`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, "[Broker ğŸ¤µ domains](<ğŸ¤µğŸ¤² Broker helper.md>)")


def replace_function_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Function`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, "[{Function} ğŸ](<{Function} ğŸ.md>)")


def replace_functions_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Functions`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, "[{Functions} ğŸ](<{Function} ğŸ.md>)")


@register_hardcoded("scripts", replacement=SCRIPTS_REPLACEMENT, token_label="Scripts")
def replace_scripts_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Scripts`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, SCRIPTS_REPLACEMENT)


def replace_item_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Item`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, "[Item ğŸ›¢](<Itemized ğŸ›¢ dataset.md>)")


def replace_items_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Items`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, "[`Items` ğŸ›¢](<Itemized ğŸ›¢ dataset.md>)")


def replace_itemizer_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Itemizer`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    replacement = "[Itemizer ğŸ›¢ helper domain](<../../ğŸ›¢ğŸ¤² Itemizer helper.md>)"
    return _replace_simple(md_files, pattern, replacement)


def replace_itemizers_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Itemizers`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    replacement = "[Itemizer ğŸ›¢ helper domains](<../../ğŸ›¢ğŸ¤² Itemizer helper.md>)"
    return _replace_simple(md_files, pattern, replacement)


def replace_talker_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Talker`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, "[Talker ğŸ˜ƒ domain](<ğŸ˜ƒ Talker role.md>)")


def replace_talkers_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Talkers`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, "[Talker ğŸ˜ƒ domains](<ğŸ˜ƒ Talker role.md>)")


def replace_itemized_dataset_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Itemized dataset`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, "[Itemized ğŸª£ dataset](<Itemized ğŸ›¢ dataset.md>)")


def replace_itemized_datasets_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Itemized datasets`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, "[Itemized ğŸª£ datasets](<Itemized ğŸ›¢ dataset.md>)")


def replace_notifier_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Notifier`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, "[Notifier ğŸ“£ domain](<ğŸ“£ğŸ‘¥ Notifier domain.md>)")


def replace_notifiers_tokens(md_files):
    pattern = re.compile(r"\{\{[\s\u00A0\u200B\u200C\u200D]*`?Notifiers`?[\s\u00A0\u200B\u200C\u200D]*\}\}", re.IGNORECASE)
    return _replace_simple(md_files, pattern, "[Notifier ğŸ“£ domains](<ğŸ“£ğŸ‘¥ Notifier domain.md>)")


def replace_triple_brace_tokens(md_files: Iterable[str], file_dict: dict[str, list[tuple[str, str]]]) -> int:
    """Replace helper tokens using triple braces with markdown links."""

    total = 0

    for md_file in md_files:
        path = Path(md_file)
        try:
            content = path.read_text(encoding="utf-8")
        except Exception:
            continue

        def replacer(match: re.Match[str]) -> str:
            token = match.group(1).strip()
            target = find_dynamic_target(token, file_dict)
            if not target:
                return match.group(0)

            try:
                rel_path = os.path.relpath(target, path.parent)
            except Exception:
                rel_path = str(target)

            link_text = format_dynamic_link_text(token, triple_brace=True)
            return f"[{link_text}](<{rel_path}>)"

        new_content, count = TRIPLE_BRACE_PATTERN.subn(replacer, content)
        if count:
            try:
                path.write_text(new_content, encoding="utf-8")
            except Exception:
                continue
            total += count

    return total


__all__ = [
    "HARDCODED_HANDLERS",
    "replace_placeholder_tokens",
    "replace_msg_tokens",
    "replace_hosts_tokens",
    "replace_host_tokens",
    "replace_issuer_tokens",
    "replace_issuers_tokens",
    "replace_vaults_tokens",
    "replace_vault_tokens",
    "replace_wallet_tokens",
    "replace_wallets_tokens",
    "replace_token_tokens",
    "replace_triple_brace_tokens",
    "replace_tokens_tokens",
    "replace_script_tokens",
    "replace_chat_tokens",
    "replace_chats_tokens",
    "replace_command_tokens",
    "replace_commands_tokens",
    "replace_settings_tokens",
    "replace_placeholders_tokens",
    "replace_domain_tokens",
    "replace_domains_tokens",
    "replace_dataset_tokens",
    "replace_datasets_tokens",
    "replace_message_tokens",
    "replace_messages_tokens",
    "replace_schema_tokens",
    "replace_schemas_tokens",
    "replace_chat_msg_tokens",
    "replace_broker_tokens",
    "replace_brokers_tokens",
    "replace_seller_tokens",
    "replace_function_tokens",
    "replace_functions_tokens",
    "replace_scripts_tokens",
    "replace_item_tokens",
    "replace_items_tokens",
    "replace_itemizer_tokens",
    "replace_itemizers_tokens",
    "replace_talker_tokens",
    "replace_talkers_tokens",
    "replace_itemized_dataset_tokens",
    "replace_itemized_datasets_tokens",
    "replace_notifier_tokens",
    "replace_notifiers_tokens",
]
